{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ebFFDVby0-GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain groq\n",
        "!pip install langchain-groq groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHlMfnRK-7Qg",
        "outputId": "eb39a9d8-db18-4bcd-ed84-f034d705d1b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.32 (from langchain)\n",
            "  Downloading langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.32->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, orjson, jsonpointer, h11, jsonpatch, httpcore, httpx, langsmith, groq, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.14 langchain-core-0.2.35 langchain-text-splitters-0.2.2 langsmith-0.1.104 orjson-3.10.7 tenacity-8.5.0\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.2.35)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (0.1.104)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.0.7)\n",
            "Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: langchain-groq\n",
            "Successfully installed langchain-groq-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2a1Uo5dMINP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Q1)  Implement a Chain-of-Thought prompting system to solve word problems. Your system should\n",
        " break down the problem-solving process into steps and show its reasoning.\n",
        " Task:\n",
        " ● Create a function that takes a word problem as input.\n",
        " ● UsetheOpenAI API or any other LLM API to generate a step-by-step solution.\n",
        " ● Theoutput should show each step of the reasoning process.\n",
        " ● Test your function with at least two word problems of varying complexity.\n",
        " Example word problem: \"A baker has 150 eggs. If each cake requires 3 eggs and each cookie\n",
        " requires 2 eggs, how many cakes and cookies can the baker make if they want to use all the\n",
        " eggs and make an equal number of each?"
      ],
      "metadata": {
        "id": "QDQZH4JqMI4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate # Import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "import os\n",
        "\n",
        "# Set your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize the Groq LLM\n",
        "llm = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
        "\n",
        "# Example of a prompt without answers\n",
        "example = \"\"\"\n",
        "Question:A baker has 150 eggs. If each cake requires 3 eggs and each cookie requires 2 eggs, how many cakes and cookies can the baker make if they want to use all the eggs and make an equal number of each?\n",
        "\"\"\"\n",
        "\n",
        "# Create a HumanMessage with the example\n",
        "human_message = HumanMessage(content=example)\n",
        "\n",
        "# Create a SystemMessage to set the context\n",
        "system_message = SystemMessage(content=\"You are a helpful assistant. Solve the following problems step by step.\")\n",
        "\n",
        "# Combine the messages into a prompt template\n",
        "prompt_template = ChatPromptTemplate.from_messages([system_message, human_message]) # Use ChatPromptTemplate\n",
        "\n",
        "# Initialize the LLMChain with the prompt and the LLM\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# Run the chain with an empty input since the prompt template includes everything needed\n",
        "response = chain.run({})\n",
        "\n",
        "print(f\"Response: {response}\")\n",
        ""
      ],
      "metadata": {
        "id": "bJXalU_cI3XR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f00d99-5519-4331-bd10-9d2972717e17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Let's solve this problem step by step:\n",
            "\n",
            "1. The baker has 150 eggs in total.\n",
            "2. Each cake requires 3 eggs, and each cookie requires 2 eggs.\n",
            "3. The baker wants to make an equal number of cakes and cookies (let's call this number x).\n",
            "4. The total number of eggs used for cakes will be 3x, and the total number of eggs used for cookies will be 2x.\n",
            "5. Since the baker is using all the eggs, we can write an equation: 3x + 2x = 150\n",
            "6. Combining the terms gives us: 5x = 150\n",
            "7. Now, let's solve for x by dividing both sides by 5: x = 150 / 5\n",
            "8. So, x = 30\n",
            "\n",
            "The baker can make 30 cakes and 30 cookies, using all their eggs and making an equal number of each.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Q3cQccXLm4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 2)  Develop a prompt-chaining system that generates a short story based on user input. The\n",
        " system should use multiple prompts in sequence, with each prompt building on the output of the\n",
        " previous one.\n",
        " Task:\n",
        " ● Create a series of at least 3 prompts that will be chained together.\n",
        " ● Thefirst prompt should ask for a genre and main character.\n",
        " ● Subsequent prompts should build on previous outputs to develop the plot and\n",
        " conclusion.\n",
        " ● Implement the chaining logic to pass information between prompts.\n",
        " ● Allow the user to input the initial genre and main character.\n",
        " ● Output the final story generated through the chain."
      ],
      "metadata": {
        "id": "kx76FnYiMfXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "import os\n",
        "\n",
        "# Set your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize the Groq LLM\n",
        "llm = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
        "\n",
        "# First prompt template: Write a short introduction about the topic\n",
        "first_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Write a short introduction about {topic}.\"\n",
        ")\n",
        "\n",
        "# Second prompt template: Suggest 3 key points based on the introduction\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"introduction\"],\n",
        "    template=\"Based on this introduction, suggest 3 key points to expand upon: {introduction}\"\n",
        ")\n",
        "\n",
        "# Third prompt template: Provide brief explanations for each of the key points\n",
        "third_prompt = PromptTemplate(\n",
        "    input_variables=[\"key_points\"],\n",
        "    template=\"For each of these key points, provide a brief explanation: {key_points}\"\n",
        ")\n",
        "# Create the chains\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt)\n",
        "# Create the sequential chain to link the individual chains\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three],\n",
        "    verbose=True\n",
        ")\n",
        "# Run the chain with a specific topic\n",
        "topic = \"deep learning\"\n",
        "result = overall_chain.run(topic)\n",
        "# Print the final result\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQbO_2Gu08BG",
        "outputId": "ad08f92b-bcc9-4b0f-b2c4-758c0ea0a9e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mDeep learning is a subset of machine learning, which is a branch of artificial intelligence (AI). It involves the use of artificial neural networks with many layers (hence \"deep\") to model and solve complex problems. These networks are capable of learning and improving their performance on a task by analyzing large amounts of data, without being explicitly programmed with task-specific rules. Deep learning has achieved state-of-the-art results in many areas, including image and speech recognition, natural language processing, and game playing. It has the potential to revolutionize many industries, from healthcare to transportation, by enabling machines to automatically learn and make decisions from data.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m1. **Artificial Neural Networks:** Deep learning relies heavily on artificial neural networks (ANNs), which are algorithms designed to simulate the way that the human brain analyzes and processes information. These networks consist of interconnected layers of nodes or \"neurons,\" and they can learn to recognize patterns and patterns in data by adjusting the weights of these connections. Deep learning networks typically have many more layers than traditional ANNs, which allows them to model and solve more complex problems.\n",
            "\n",
            "2. **Learning from Data:** One of the key advantages of deep learning is its ability to learn and improve its performance on a task by analyzing large amounts of data. This is in contrast to traditional machine learning algorithms, which often require human experts to manually engineer features or rules for the task at hand. Deep learning networks can automatically discover the relevant features and patterns in the data, which makes them more flexible and adaptable to a wide range of tasks.\n",
            "\n",
            "3. **Potential Applications:** Deep learning has already achieved state-of-the-art results in many areas, including image and speech recognition, natural language processing, and game playing. However, its potential applications extend far beyond these domains. For example, in healthcare, deep learning could be used to analyze medical images and diagnose diseases, or to predict patient outcomes based on their medical history. In transportation, deep learning could be used to optimize traffic flow and reduce congestion, or to enable self-driving cars to navigate complex environments. Overall, deep learning has the potential to revolutionize many industries by enabling machines to automatically learn and make decisions from data.\u001b[0m\n",
            "\u001b[38;5;200m\u001b[1;3m1. Artificial Neural Networks (ANNs): ANNs are a type of machine learning model inspired by the structure and function of the human brain. They consist of interconnected layers of nodes or \"neurons,\" and they learn to recognize patterns and make predictions by adjusting the weights of these connections. Deep learning networks are a type of ANN that have many layers, allowing them to model and solve more complex problems than traditional ANNs.\n",
            "2. Learning from Data: Deep learning models learn from data by analyzing large amounts of examples and adjusting the weights of the connections in the network. This allows them to automatically discover the relevant features and patterns in the data, without the need for human experts to manually engineer features or rules. This makes deep learning models more flexible and adaptable to a wide range of tasks, as they can learn to recognize patterns in data that may not be easily captured by traditional machine learning models.\n",
            "3. Potential Applications: Deep learning has already achieved state-of-the-art results in many areas, such as image and speech recognition, natural language processing, and game playing. However, its potential applications extend far beyond these domains. Deep learning could be used in healthcare to analyze medical images and diagnose diseases, or to predict patient outcomes based on their medical history. In transportation, deep learning could be used to optimize traffic flow and reduce congestion, or to enable self-driving cars to navigate complex environments. Overall, deep learning has the potential to revolutionize many industries by enabling machines to automatically learn and make decisions from data.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "1. Artificial Neural Networks (ANNs): ANNs are a type of machine learning model inspired by the structure and function of the human brain. They consist of interconnected layers of nodes or \"neurons,\" and they learn to recognize patterns and make predictions by adjusting the weights of these connections. Deep learning networks are a type of ANN that have many layers, allowing them to model and solve more complex problems than traditional ANNs.\n",
            "2. Learning from Data: Deep learning models learn from data by analyzing large amounts of examples and adjusting the weights of the connections in the network. This allows them to automatically discover the relevant features and patterns in the data, without the need for human experts to manually engineer features or rules. This makes deep learning models more flexible and adaptable to a wide range of tasks, as they can learn to recognize patterns in data that may not be easily captured by traditional machine learning models.\n",
            "3. Potential Applications: Deep learning has already achieved state-of-the-art results in many areas, such as image and speech recognition, natural language processing, and game playing. However, its potential applications extend far beyond these domains. Deep learning could be used in healthcare to analyze medical images and diagnose diseases, or to predict patient outcomes based on their medical history. In transportation, deep learning could be used to optimize traffic flow and reduce congestion, or to enable self-driving cars to navigate complex environments. Overall, deep learning has the potential to revolutionize many industries by enabling machines to automatically learn and make decisions from data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q 3)Implement a Tree-of-Thought prompting system to solve a complex problem. The system should\n",
        " explore multiple paths of reasoning and select the most promising one.\n",
        " Task:\n",
        " ● Create a function that takes a complex problem as input.\n",
        " ● Generate at least 3 different initial approaches to solving the problem.\n",
        " ● Foreachapproach, develop 2-3 possible next steps.\n",
        " ● Implement a method to evaluate the promise of each path.\n",
        " ● Select the most promising path and generate a final solution.\n",
        " ● Test your system with the following problem"
      ],
      "metadata": {
        "id": "3dM2BMbuRJRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "import os\n",
        "\n",
        "# Set your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize the Groq LLM\n",
        "llm = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
        "\n",
        "# Define the base prompt template\n",
        "base_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"thoughts\"],\n",
        "    template=\"\"\"Question: {question}\n",
        "\n",
        "Let's approach this step-by-step:\n",
        "\n",
        "{thoughts}\n",
        "\n",
        "Based on these thoughts, what is the final answer?\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Define examples for few-shot learning\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"What is 15 + 27?\",\n",
        "        \"thoughts\": \"\"\"1) First, let's break down the numbers: 15 is 10 + 5, and 27 is 20 + 7.\n",
        "2) We can rearrange these: (10 + 20) + (5 + 7)\n",
        "3) 10 + 20 = 30\n",
        "4) 5 + 7 = 12\n",
        "5) So now we have 30 + 12\n",
        "6) 30 + 12 = 42\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How many months have 28 days?\",\n",
        "        \"thoughts\": \"\"\"1) Let's think about this carefully. At first, we might think only February has 28 days.\n",
        "2) However, the question is asking how many months HAVE 28 days, not how many ONLY have 28 days.\n",
        "3) Every month has at least 28 days.\n",
        "4) Therefore, all 12 months have at least 28 days.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create the few-shot prompt template\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=PromptTemplate(\n",
        "        input_variables=[\"question\", \"thoughts\"],\n",
        "        template=\"Question: {question}\\n\\nThoughts: {thoughts}\"\n",
        "    ),\n",
        "    prefix=\"Here are some examples of breaking down questions into steps:\",\n",
        "    suffix=\"Now, let's approach a new question:\\n\\n{input}\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# Combine the few-shot examples with the base prompt\n",
        "final_prompt = few_shot_prompt.format(\n",
        "    input=base_prompt.template\n",
        ")\n",
        "\n",
        "# Create the LLMChain\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"question\", \"thoughts\"],\n",
        "        template=final_prompt\n",
        "    )\n",
        ")\n",
        "\n",
        "# Use the chain\n",
        "question = \"If a train travels 120 km in 2 hours, what is its average speed in km/h?\"\n",
        "thoughts = \"Let's break this down step by step:\"\n",
        "result = chain.run({\"question\": question, \"thoughts\": thoughts})\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "aF95iVDWZvxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a536f6a-10bb-4e9d-9f65-c3e8626bd8b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the average speed of the train, we can use the formula:\n",
            "\n",
            "Average Speed = Distance / Time\n",
            "\n",
            "In this case, the distance is 120 km and the time is 2 hours. So,\n",
            "\n",
            "Average Speed = 120 km / 2 hours\n",
            "\n",
            "Average Speed = 60 km/h\n",
            "\n",
            "The train's average speed is 60 kilometers per hour.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFWqx_rX1eu5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}